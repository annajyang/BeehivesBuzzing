{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1fd1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "from utilsBeehiveState import report_SVM_beehiveState_results, SVM_Classification_BeehiveSTATE\n",
    "import librosa\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "sys.path.append('/Users/annayang/Documents/QueenBee/Bee_NotBee_classification')\n",
    "\n",
    "from utils import raw_feature_fromSample, get_samples_id_perSet, get_GT_labels_fromFiles, labels2binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0a884c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_audio_labels='/Users/annayang/Documents/QueenBee/MyDataset'+os.sep  # path where to save audio segments and labels files.\n",
    "path_raw_state_labels = '/Users/annayang/Documents/QueenBee/MyDataset/state_labels.csv'\n",
    "path_images='/Users/annayang/Documents/QueenBee/updatedDataset'+os.sep\n",
    "path_save_images='/Users/annayang/Documents/QueenBee/croppedDataset'+os.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614f6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids_test, sample_ids_train, sample_ids_val = get_samples_id_perSet(path_save_audio_labels+'split_random_0.json')\n",
    "\n",
    "labels2read = 'state_labels'\n",
    "labels_train = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_train, labels2read)\n",
    "Y_train= labels2binary('missing queen', labels_train)\n",
    "\n",
    "labels_val = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_val, labels2read)\n",
    "Y_val= labels2binary('missing queen', labels_val)\n",
    "\n",
    "labels_test = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_test, labels2read)\n",
    "Y_test= labels2binary('missing queen', labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebda16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(sample_ids_train):\n",
    "    im = Image.open(path_images+'train/'+str(Y_train[i])+'/'+filename[:-4]+'.png')\n",
    "    im_crop = im.crop((85, 70, 500, 400))\n",
    "    im_crop.save((path_save_images+'train/'+str(Y_train[i])+'/'+filename[:-4]+'.png'), quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bc2ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(sample_ids_test):\n",
    "    im = Image.open(path_images+'test/'+str(Y_test[i])+'/'+filename[:-4]+'.png')\n",
    "    im_crop = im.crop((85, 70, 500, 400))\n",
    "    im_crop.save((path_save_images+'test/'+str(Y_test[i])+'/'+filename[:-4]+'.png'), quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e21abb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(sample_ids_val):\n",
    "    im = Image.open(path_images+'val/'+str(Y_val[i])+'/'+filename[:-4]+'.png')\n",
    "    im_crop = im.crop((85, 70, 500, 400))\n",
    "    im_crop.save((path_save_images+'val/'+str(Y_val[i])+'/'+filename[:-4]+'.png'), quality=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
