{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a199bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from utilsBeehiveState import report_SVM_beehiveState_results, SVM_Classification_BeehiveSTATE\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "\n",
    "sys.path.append('/Users/annayang/Documents/QueenBee/Bee_NotBee_classification')\n",
    "\n",
    "from utils import raw_feature_fromSample, get_samples_id_perSet, get_GT_labels_fromFiles, labels2binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f31315",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save_audio_labels='/Users/annayang/Documents/QueenBee/MyDataset'+os.sep  # path where to save audio segments and labels files.\n",
    "path_raw_state_labels = '/Users/annayang/Documents/QueenBee/MyDataset/state_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1842edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids_test, sample_ids_train, sample_ids_val = get_samples_id_perSet(path_save_audio_labels+'split_random_0.json')\n",
    "\n",
    "labels2read = 'state_labels'\n",
    "labels_train = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_train, labels2read)\n",
    "Y_train= labels2binary('missing queen', labels_train)\n",
    "\n",
    "labels_val = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_val, labels2read)\n",
    "Y_val= labels2binary('missing queen', labels_val)\n",
    "\n",
    "labels_test = get_GT_labels_fromFiles(path_save_audio_labels, sample_ids_test, labels2read)\n",
    "Y_test= labels2binary('missing queen', labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf89e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-09--04-12-49_1__segment1\n"
     ]
    }
   ],
   "source": [
    "print(sample_ids_test[0][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8e4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(sample_ids_test):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if Y_test[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/test/0/' + sample[:-4] + '.png')\n",
    "    elif Y_test[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/test/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9cb2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(sample_ids_train):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if Y_train[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/train/0/' + sample[:-4] + '.png')\n",
    "    elif Y_train[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/train/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1cea136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(sample_ids_val):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if Y_val[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/val/0/' + sample[:-4] + '.png')\n",
    "    elif Y_val[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/updatedDataset/val/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c84345",
   "metadata": {},
   "source": [
    "# their data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "551d8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_path_save_audio_labels='/Users/annayang/Documents/QueenBee/Dataset'+os.sep  # path where to save audio segments and labels files.\n",
    "old_path_raw_state_labels = '/Users/annayang/Documents/QueenBee/Dataset/state_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce9fbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sample_ids_test, old_sample_ids_train, old_sample_ids_val = get_samples_id_perSet(old_path_save_audio_labels+'split_random_0.json')\n",
    "\n",
    "labels2read = 'state_labels'\n",
    "old_labels_train = get_GT_labels_fromFiles(old_path_save_audio_labels, old_sample_ids_train, labels2read)\n",
    "old_Y_train= labels2binary('missing queen', old_labels_train)\n",
    "\n",
    "old_labels_val = get_GT_labels_fromFiles(old_path_save_audio_labels, old_sample_ids_val, labels2read)\n",
    "old_Y_val= labels2binary('missing queen', old_labels_val)\n",
    "\n",
    "old_labels_test = get_GT_labels_fromFiles(old_path_save_audio_labels, old_sample_ids_test, labels2read)\n",
    "old_Y_test= labels2binary('missing queen', old_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4af22956",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(old_sample_ids_test):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(old_path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if old_Y_test[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/test/0/' + sample[:-4] + '.png')\n",
    "    elif old_Y_test[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/test/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12dbe26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(old_sample_ids_train):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(old_path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if old_Y_train[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/train/0/' + sample[:-4] + '.png')\n",
    "    elif old_Y_train[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/train/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "def37686",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(old_sample_ids_val):\n",
    "    high_level_features = 0\n",
    "    raw_feature = 'MFCCs20'\n",
    "    # raw feature extraction:\n",
    "    x = raw_feature_fromSample(old_path_save_audio_labels+sample, raw_feature ) # x.shape: (4, 20, 2584)\n",
    "    x_norm = x\n",
    "\n",
    "#     #normalization here:\n",
    "#     if not normalization == 'NO':\n",
    "#         x_norm = featureMap_normalization_block_level(x, normalizationType = normalization) \n",
    "#     else: x_norm = x\n",
    "\n",
    "    if high_level_features:\n",
    "        # high level feature extraction:\n",
    "        if 'MFCCs' in raw_feature:\n",
    "            X = compute_statistics_overMFCCs(x_norm, 'yes') # X.shape: (4 , 120)\n",
    "        else: \n",
    "            X = compute_statistics_overSpectogram(x_norm)\n",
    "\n",
    "        feature_map=X\n",
    "    else:\n",
    "        feature_map=x_norm\n",
    "        \n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = librosa.display.specshow(feature_map, ax=ax, y_axis='log', x_axis='time')\n",
    "    \n",
    "    if old_Y_val[i] == 0:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/val/0/' + sample[:-4] + '.png')\n",
    "    elif old_Y_val[i] == 1:\n",
    "        fig.savefig('/Users/annayang/Documents/QueenBee/theirUpdatedDataset/val/1/' + sample[:-4] + '.png')\n",
    "    else:\n",
    "        print('error no label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4bbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
